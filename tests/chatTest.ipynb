{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "aikey = os.getenv('OPENAI_API_KEY')\n",
    "orgkey = os.getenv('OPENAI_ORG_KEY')\n",
    "print(aikey)\n",
    "# pathtocert = os.path('C:/Users/P3159331\\Downloads\\Charter Communications Root Certification Authority.crt')\n",
    "\n",
    "openai.api_key = aikey\n",
    "openai.organization = orgkey\n",
    "\n",
    "os.environ['REQUESTS_CA_BUNDLE'] = 'C:/Users/P3159331/Downloads/CharterRootCert.crt'\n",
    "\n",
    "\n",
    "os.getenv('OPEN_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class regex_in:\n",
    "    string: str\n",
    "\n",
    "    def __eq__(self, other: str | re.Pattern):\n",
    "        if isinstance(other, str):\n",
    "            other = re.compile(other)\n",
    "        assert isinstance(other, re.Pattern)\n",
    "        # TODO extend for search and match variants\n",
    "        return other.fullmatch(self.string) is not None\n",
    "\n",
    "# Clean up the a line of text, return None if its a timestamp or blank line\n",
    "def cleanLine(line):\n",
    "    match regex_in(line):\n",
    "        case r'\\d+ .*':\n",
    "            #If its a speaker/heading tag\n",
    "            firstremoved = re.sub('\\d+ \"','',line)\n",
    "            nameonly = re.sub('\" .*',':',firstremoved)\n",
    "            return nameonly\n",
    "        case r'[0-9][0-9].*': \n",
    "            return None\n",
    "        case r'[A-Za-z].*': \n",
    "            return line\n",
    "\n",
    "        case '': \n",
    "            return None\n",
    "with open('julyaTranscript.vtt') as f:\n",
    "    myr = f.read()\n",
    "lines = myr.splitlines()\n",
    "\n",
    "output = []\n",
    "previous_speaker = ''\n",
    "for line in lines: \n",
    "    newline = cleanLine(line)\n",
    "    if newline != None: \n",
    "        if newline[-1] == ':':\n",
    "            current_speaker = newline\n",
    "            if current_speaker != previous_speaker:\n",
    "                #print(newline) \n",
    "                previous_speaker = current_speaker\n",
    "                output.append(newline)\n",
    "        else: \n",
    "            #print(newline) \n",
    "            output.append(newline)\n",
    "final = '\\n'.join(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_transcript(transcript): \n",
    "    chunks = []\n",
    "    splitter = (len(transcript)//7500)+1\n",
    "    chunklen = len(transcript)//splitter+1 \n",
    "    for i in range(1, splitter+1):\n",
    "        index1 = (i-1) * chunklen\n",
    "        index2 = i * chunklen\n",
    "        print(f'index1: {index1} index2: {index2}')\n",
    "        chunks.append(transcript[index1:index2])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index1: 0 index2: 5177\n",
      "index1: 5177 index2: 10354\n",
      "index1: 10354 index2: 15531\n"
     ]
    }
   ],
   "source": [
    "# Okay So now i want to break it up, 7500 characters at a time\n",
    "# print(len(final))\n",
    "# print(len(final)//7500)\n",
    "chunks = []\n",
    "splitter = (len(final)//7500)+1\n",
    "chunklen = len(final)//splitter+1 \n",
    "for i in range(1, splitter+1):\n",
    "    index1 = (i-1) * chunklen\n",
    "    index2 = i * chunklen\n",
    "    print(f'index1: {index1} index2: {index2}')\n",
    "    chunks.append(final[index1:index2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"WEBVTT\\nNathan Hess:\\nLooks really well.\\nDoes the recording get sent to all of us or just me do you know how it works? It'll get sent it'll get sent to you and then you can share it, but it also it transcribes everything in real time. So there's Jack.\\nJack just dump that transcription into 1 of these generative ai tools and it.\\nThat pretty decent meeting summary, right?\\nRyan Richards:\\nShockingly good. Yeah.\\nJulya Fridman:\\nLike, into chat chat or something.\\nNathan Hess:\\nYeah, I'll share with you. We did that. We tested this out on the.\\nMichael call a few weeks ago and.\\nIt worked for really well and so now.\\nAnd I'm super excited about it. Wow.\\nJulya Fridman:\\nYeah, okay.\\nNathan Hess:\\nI mean, you still have to go back through and do a little editing or whatever, but you would have to do that. Even if you were taking super detailed notes at the same time. So.\\nJulya Fridman:\\nVery cool. Yeah.\\nRyan Richards:\\nWell, do we want to start with, um, Julie? I don't know if you have any.\\nUpdates beyond what John wells has been sending out this morning on the upgrade and impact on that. Do you have anything else?\\nJulya Fridman:\\nUm, I do have a little bit of an update on the Apple issue. Um, we, we had a call with Hi this morning.\\nWhere he walked us through his proposed fixed.\\nUm, they're still working on it, um, but they, they believe they have a solution. It's not without, uh, some.\\nUh, errors, um, but I think the bulk of the viewership can be restored, but there, he was walking us through John wells and I, through, um, some graphs that showed.\\nUm, you know, in about 80% of cases.\\nUh, the appropriate network can be mapped to, uh, to the viewership or the, the viewership for the appropriate network and get extracted. However, in about 20% of the cases, um, they. they\\nAre not able to follow so they know that the customer, for example, is starting with spectrum news, but they cannot see what happens afterwards. And so, uh, the question was.\\nUh, what do we want to do with that data? Do we just, uh, not assign a network and program to it but just put it in some, um, bucket.\\nOf usage where, you know, for us overall, we will know that.\\nViewership happened somewhere, but we wouldn't be able to attribute it to a particular network and so.\\nWe decided that, you know, for spectrum news, and for all the rest of the networks, uh, in those instances, we should just put it in all other usage bucket.\\nSo, um, every network's viewership will be slightly understated. Um, but not not by.\\nYou know, 5 to 10%, uh, but at least we'll get the bulk of the data back end. So, I don't think for you guys given that, it's just Apple TV data. I don't think it's gonna be dramatically.\\nYou know, dramatically will impact, um, any trending given that we'll probably have about 90% of viewership back in.\\nSo, okay, so then, that yeah, do they have a sense of was it con, the, the 20% of.\\nRyan Richards:\\nAccounts that they can't correctly map. Is that kind of spread out across.\\nJulya Fridman:\\nGeographies customer types. Yeah. Yeah. It seems it seemed like it was spread out.\\nAcross across apps.\\nSo, for spectrum for SDA, and for, I didn't, I didn't ask about.\\nThat's a good point. I didn't ask about geographies.\\nUm, so, let me, uh, let me ping him and see if he can look at it. Uh.\\nBy geography by market to see if there is any patterns there.\\nOkay.\\nBut that's the only update I have, I don't know, gave, em, if you have anything.\\nGuillaume Schwengler:\\nMm, hmm while you've seen the upgrade 1 through over this weekend.\\nSo, now I will be working and reloading the March, uh, data aggregate. They didn't get to do it before the gate. So.\\nThere are time to do February and then I'm working on March so will soon have the engagement numbers for March 2023.\\nNathan Hess:\\nYou've been looking at the February data, and it's been reloaded at all.\\nGuillaume Schwengler:\\nI haven't yet. No, I was planning to do it today.\\nYou've seen something that's off, uh.\\nNathan Hess:\\nNot necessarily off, um.\\nThat is what we are looking at earlier right? Ryan.\\nRyan Richards:\\nWhich 1, are you referring to.\\nNathan Hess:\\nThe share.\\nUh, and the Android device data.\\nRyan Richards:\\nUh, well, I don't think that was particular to February, so.\\nWe yeah, we pull the topics. Sorry.\\nUm, pulled.\\nThe share viewership coming from set top box and then our apps.\\nAnd with whatever data fixes happen, and it seems to have.\\nSignificantly changed those from what we had as a.\\nAs recently a couple of months ago, I think.\\nUm, so now, FDA is like, 32, almost of all of our viewership.\\nOr set top boxes 68.\\nDoes that surprise you at all Jim and Julia?\\nGuillaume Schwengler:\\nWe had that number somewhere.\\nJulya Fridman:\\nBut it went from from the teams to 38%.\\nRyan Richards:\\nQ, and what was the, what was the latest percent you had on hand?\\nYou 1st shared with me uh, it was 24%.\\nKeelan Gallagher:\\nBut from an older dataset that we had pulled, I'm guessing in March.\\nRyan Richards:\\nYeah, oh, yeah, I see it on the thread now. So from March earlier this year that we had pulled 26%.\\nJulya Fridman:\\nHold on, it seems high to.\\nI have open somewhere.\\nSo overall.\\nAcross all networks set, top boxes. 83% is.\\nRyan Richards:\\nAll of our video new households. Oh, yeah. Is that households are viewing ours?\\nJulya Fridman:\\nOh, if possible, I, I believe it. Yeah, no uh, not not usage right? Households.\\nKeelan Gallagher:\\nAnd we can pull the usage, we can pull like, station hours.\\nJulya Fridman:\\nIf you can pull usage, uh, that would be.\\nUh, easier to compare. Okay.\\nGuillaume Schwengler:\\nThe latest number I found in 1 of the decks I heard was August 2022. I had usage, um, 16.\\nAnd the rest was set top box it changes a little bit by markets.\\nLike, Florida was most 17%, New York City.\\nJulya Fridman:\\nRelease I wouldn't expect any job. Like, it's just the.\\nRight. Like oh, wait, wait, wait, we fixed Android.\\nUh, in this data, right? Right.\\nUm, but that's but the Android issue started.\\nIn February, so if you compare it to January.\\nI mean, it should be in line.\\nRyan Richards:\\nAll right okay. And can you work with Jim? Can you just show them how you pull the data? The exact data you have? Because those numbers are and.\\nI want to get that straight, um.\\nKeelan Gallagher:\\nYeah, we'll pull we'll pull station hours and we'll we'll look at it at.\\nJulya Fridman:\\nYeah, Jim, Jim, you have different you, you've created different trending, right?\\nGuillaume Schwengler:\\nUh, I think, no, we had 1 is a pie chart when we tracked the launch of the apps where we had, I was coming from set the box I was coming from and I was coming from the up.\\nJulya Fridman:\\nBut then tracking it, but do you have anything more recent than, uh, since the launch of the apps? That would have been a few years ago, right?\\nGuillaume Schwengler:\\nThis 1 was the latest I was August 2022.\\nRight. Um, let's see, you.\\nJulya Fridman:\\nBut either way, I mean, if we pull January data and compare it to.\\nUm, the new restate the data it shouldn't directionally be dramatically different. I don't think.\\nKeelan Gallagher:\\nI'm running it right now. I'll probably know now, in a few minutes.\\nRyan Richards:\\nOkay on that topic I wanted to check in to see Julie. I think you said, oh, a little while back you're going to connect with someone on the latest from.\\nWhat Katy, Donna and her team, like next steps for power on on.\\nShe told me last week.\\nJulya Fridman:\\nUh, that she did not, uh, get anything back from Katie. Uh.\\nMaybe we just need to what, what exactly she is, she investigating.\\nThe pylon or the so.\\nRyan Richards:\\nFrom that last time that we all met together, it.\\nNathan, and, and step in here too, if there's anything I'm missing here, but the, what I recall is that on Apple TV, we, we need to switch up the rules for, like, what constitutes power on. Right?\\nBecause as it currently stands, you have to close out of the app for it to.\\nAnd power on to spectrum news. Okay. Um, so it's really about like, redefining what exactly power on means on the connected.\\nTv device apps that was specific to Apple TV, right?\\nYeah, but we should, we should make sure that it's aligned across all the platforms because.\\nWho knows for the other ones, if there's slight differences that could make a significant impact on the actual.\\nAmount of times people are saying spectrum is when it comes on.\\nJulya Fridman:\\nSo, it's basically, if you, if you get out of the app and then come back within a certain period of time.\\nIt doesn't, uh, power on you, uh, unless unless you've been out.\\nRyan Richards:\\nFor a certain number of hours, right? I mean, what I recall for Apple TV, I don't think there was an hour limit is like, you could be out of it for a week. And as long as you didn't actually close out of that app manually on the Apple TV.\\nInterface then you're still not going to power on to the spectrum news.\\nNathan Hess:\\nYeah, that's right. Yeah. I don't know about the week's part, but yeah, like that.\\nOurs could go by and you could do any number of other viewing events on other apps and come back.\\nTo the spectrum news app, or come back to and it would still power on 2.\\nGo back to what you were watching when you finished your last session.\\nJulya Fridman:\\nBecause then you wouldn't test with this. Yeah, we tested it pretty extensively with last fall.\\nNathan Hess:\\nShe had a whole list of, like, if Dan's that we went through, I can, I can.\\nProbably surface, at least my responses to that.\\nJulya Fridman:\\nAnd from Katie, WH, uh, what do we need from from Katie the confirmation or the, um.\\nRyan Richards:\\nNo, I don't think we need confirmation. We just need to know next steps of how we actually change the power on rules. And, like I wonder, I'm not sure if that's.\\nJulya Fridman:\\nDo you think that's Katie? I'm not sure. I think it's I think it's we need to go to the product person for Apple TV.\\nAnd work with them, shouldn't we? Uh, there was somebody, uh, when this whole Apple issue came up, um.\\nRocky ping me, and she had somebody on the on the call with her who was the product manager for Apple TV?\\nUm, I can see if I can get her name.\\nAnd maybe maybe we can just talk to her.\\nRyan Richards:\\nOkay, how it works.\\nJulya Fridman:\\nGet the product person.\\nOkay, let me let me look into it.\\nThanks, Sarah is so busy in her new world. It's like, impossible to get a hold of her. So, let me let me deal with it.\\nRyan Richards:\\nSounds good, thank you. Um.\\nWhat else heads up we.\\nYou got confirmation that the power on fix rolled out successfully last week, and they didn't see any notice will increase in call volume to call centers. So, that was good.\\nJulya Fridman:\\nUm, so we'll.\\nRyan Richards:\\nWait until the viewership data is good to pull. The recent may dealership. Data is good following this city upgrade and.\\nThen we can validate on our end that we're saying, hopefully.\\nThe impact of the fix perfect.\\nSighting yes, and also we were just our team was just meeting before this also exciting knowing that.\\nUh, there's definitely didn't fix everything, so hopefully we see a positive impact and then we regroup and figure out. All right what are the gaps.\\nThat we still see and get those addressed eventually.\\nYeah, 1 of our analysts moved to Florida in the fall and didn't get spec, news is power on and hers was not fixed last week. So.\\nWe know that there are issues post November like this fix was supposed to capture that whatever issues happen between March and November last year. Um, we know that there have been continued issues since November per the data.\\nThat and analysis you all did, and anecdotally.\\nFor example, Mike, a month or so ago, getting his new box in and not coming with spectrum uses power on in New York City.\\nUm, and then clearly, there's at least 1 person who, even in that period of last year didn't get there is fixed. So.\\nMore to come.\\nJulya Fridman:\\nSounds good Nathan. Anything else on your end.\\nNathan Hess:\\nNothing from me, How's that query? Coming along?\\nKeelan Gallagher:\\nIt's coming as soon as I guess I'll send it to the group if we're not still on the call.\\nYeah, I don't think I have.\\nNathan Hess:\\nAnything else top of mind.\\nFor a moment, we'll probably be reaching out.\\nYou have a bunch this week and next just to make sure that we're seeing the same stuff in the in the reloaded data, but.\\nAs long as you'll be around, we'll look forward to chatting with you and yeah. You know, we're hoping.\\nTo probably send out both March and april's engagement report. By the end of the month. I had initially said.\\nThe 19th, but I don't think that's gonna happen. So if we can get it out by the.\\n2526 or 31st that'd be great.\\nYeah, and are you taking any sorry? Are you taking any time off for Memorial day, or you'd be around.\\nTo validate, I'll do it around.\\nGuillaume Schwengler:\\nPriority number 1.\\nNathan Hess:\\nYeah, uh, Kim would, would you run your type.\\nJulya Fridman:\\nAnalysis of of the new data yes you can see.\\nThe gaps, yes, that way Jim has created like a tracker. That's.\\nI mean, it goes, it's it's not spectrum news specific. It's more just overall, um, to kind of.\\nUh, uh, and, uh, you know, hopefully some things will pop up.\\nIf, uh, some red flags, we'll, we'll see some red flags if there's.\\nAny data issue and then reload.\\nNathan Hess:\\nSo, I had had John wells load a mapping file that maps line up to spectrum news feed.\\nRegion and market in the sandbox, I mean, uh.\\nYeah, I'll share that link with you. It's helpful for a lot of our reporting takes out of Excel step for us. So, I mean, hopefully that mapping is current, but.\\nAndy, I need to have that environment.\\nGuillaume Schwengler:\\nNice and we're starting to see more and more relating to spectrum .\\nSo, we got keeping track of it for now, but you let us know how you want to report on it because we'll be able to add later on similar to how we do for spectrum use and Tableau. If you want to look at monthly.\\nIt'd be good to know. Yeah. I don't know.\\nNathan Hess:\\nYeah, I haven't I haven't personally, I thought.\\nI thought too deeply on what those reports might look like Ryan. I don't know if you have.\\nThoughts on that for plans.\\nRyan Richards:\\nNo, not yet. Not yet. Cool.\\nGuillaume Schwengler:\\nTbd, and with the apps, so the last quarter we had done by bundled so that we get more or less the same numbers. And what has.\\nIn order to know the product bundle of the app.\\nSo, we also keep updating that to see if there's a significant change for users or mobile app users, but we can.\\nAt least on the relative bases and index values, we could report on it. If you want it.\\nIs that sell for spectrum news plus? Or is this so India you have your ship for both that we see coming through the spectrum use local feed and then the spectrum use plus feed.\\nBut also, among our users authenticated users that are customers of charter over, we do the product bundle information as a customer to got it.\\nGot it cool.\\nNathan Hess:\\nAnything else I can walk on with Michael likes to say.\\nFor that John Mike, I think.\\nJulya Fridman:\\nYeah, we're good. Love that.\\nCool. Cool. Thanks guys. Well, hopefully, no data issues.\\nNathan Hess:\\nFingers crossed. Yeah. It seems like it's going well so far. So.\\nI was happy to see that the upgrade went through smoothly this morning. Everything was back up on line.\\nKim actually said that the DB seemed to be performing pretty well this morning. So.\\nI love that.\\nJulya Fridman:\\nThat'd be nice if there is, there was a side effect.\\nNathan Hess:\\nYeah, right yeah cleared out all the old zombie jobs.\\nJulya Fridman:\\nAll right cool. Talk to you guys soon.\\nRyan Richards:\\nHi guys bye.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[0:16531]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "<empty message>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Okay so I want to play around and have this function remove all the junk to have it most optimally fed into chat GPT, I want to keep the names and the tex: \u001b[39;00m\n\u001b[0;32m      3\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39msk-Zbyc4jAQJhNT79ABwIUbT3BlbkFJZyo5ZCLXxZym5WzIJAS\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m response3 \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m, prompt\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mCan you summarize this transcript for me?: \u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m{\u001b[39;49;00mfinal\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, temperature\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, max_tokens\u001b[39m=\u001b[39;49m\u001b[39m600\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\P3159331\\Documents\\Local\\meeting_summarazation\\venv\\Lib\\site-packages\\openai\\api_resources\\completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\P3159331\\Documents\\Local\\meeting_summarazation\\venv\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\P3159331\\Documents\\Local\\meeting_summarazation\\venv\\Lib\\site-packages\\openai\\api_requestor.py:230\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    211\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    219\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    220\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    221\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    222\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\P3159331\\Documents\\Local\\meeting_summarazation\\venv\\Lib\\site-packages\\openai\\api_requestor.py:624\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    617\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    618\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    619\u001b[0m         )\n\u001b[0;32m    620\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    621\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 624\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    625\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    626\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    627\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    628\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    629\u001b[0m         ),\n\u001b[0;32m    630\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    631\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\P3159331\\Documents\\Local\\meeting_summarazation\\venv\\Lib\\site-packages\\openai\\api_requestor.py:687\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    685\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    686\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 687\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    688\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    689\u001b[0m     )\n\u001b[0;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mAuthenticationError\u001b[0m: <empty message>"
     ]
    }
   ],
   "source": [
    "# Okay so I want to play around and have this function remove all the junk to have it most optimally fed into chat GPT, I want to keep the names and the tex: \n",
    "\n",
    "openai.api_key\n",
    "response3 = openai.Completion.create(model=\"gpt-3.5-turbo\", prompt=f\"Can you summarize this transcript for me?: \\n\\n {final}\", temperature=0, max_tokens=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"WEBVTT\\nNathan Hess:\\nLooks really well.\\nDoes the recording get sent to all of us or just me do you know how it works? It'll get sent it'll get sent to you and then you can share it, but it also it transcribes everything in real time. So there's Jack.\\nJack just dump that transcription into 1 of these generative ai tools and it.\\nThat pretty decent meeting summary, right?\\nRyan Richards:\\nShockingly good. Yeah.\\nJulya Fridman:\\nLike, into chat chat or something.\\nNathan Hess:\\nYeah, I'll share with you. We did that. We tested this out on the.\\nMichael call a few weeks ago and.\\nIt worked for really well and so now.\\nAnd I'm super excited about it. Wow.\\nJulya Fridman:\\nYeah, okay.\\nNathan Hess:\\nI mean, you still have to go back through and do a little editing or whatever, but you would have to do that. Even if you were taking super detailed notes at the same time. So.\\nJulya Fridman:\\nVery cool. Yeah.\\nRyan Richards:\\nWell, do we want to start with, um, Julie? I don't know if you have any.\\nUpdates beyond what John wells has been sending out this morning on the upgrade and impact on that. Do you have anything else?\\nJulya Fridman:\\nUm, I do have a little bit of an update on the Apple issue. Um, we, we had a call with Hi this morning.\\nWhere he walked us through his proposed fixed.\\nUm, they're still working on it, um, but they, they believe they have a solution. It's not without, uh, some.\\nUh, errors, um, but I think the bulk of the viewership can be restored, but there, he was walking us through John wells and I, through, um, some graphs that showed.\\nUm, you know, in about 80% of cases.\\nUh, the appropriate network can be mapped to, uh, to the viewership or the, the viewership for the appropriate network and get extracted. However, in about 20% of the cases, um, they. they\\nAre not able to follow so they know that the customer, for example, is starting with spectrum news, but they cannot see what happens afterwards. And so, uh, the question was.\\nUh, what do we want to do with that data? Do we just, uh, not assign a network and program to it but just put it in some, um, bucket.\\nOf usage where, you know, for us overall, we will know that.\\nViewership happened somewhere, but we wouldn't be able to attribute it to a particular network and so.\\nWe decided that, you know, for spectrum news, and for all the rest of the networks, uh, in those instances, we should just put it in all other usage bucket.\\nSo, um, every network's viewership will be slightly understated. Um, but not not by.\\nYou know, 5 to 10%, uh, but at least we'll get the bulk of the data back end. So, I don't think for you guys given that, it's just Apple TV data. I don't think it's gonna be dramatically.\\nYou know, dramatically will impact, um, any trending given that we'll probably have about 90% of viewership back in.\\nSo, okay, so then, that yeah, do they have a sense of was it con, the, the 20% of.\\nRyan Richards:\\nAccounts that they can't correctly map. Is that kind of spread out across.\\nJulya Fridman:\\nGeographies customer types. Yeah. Yeah. It seems it seemed like it was spread out.\\nAcross across apps.\\nSo, for spectrum for SDA, and for, I didn't, I didn't ask about.\\nThat's a good point. I didn't ask about geographies.\\nUm, so, let me, uh, let me ping him and see if he can look at it. Uh.\\nBy geography by market to see if there is any patterns there.\\nOkay.\\nBut that's the only update I have, I don't know, gave, em, if you have anything.\\nGuillaume Schwengler:\\nMm, hmm while you've seen the upgrade 1 through over this weekend.\\nSo, now I will be working and reloading the March, uh, data aggregate. They didn't get to do it before the gate. So.\\nThere are time to do February and then I'm working on March so will soon have the engagement numbers for March 2023.\\nNathan Hess:\\nYou've been looking at the February data, and it's been reloaded at all.\\nGuillaume Schwengler:\\nI haven't yet. No, I was planning to do it today.\\nYou've seen something that's off, uh.\\nNathan Hess:\\nNot necessarily off, um.\\nThat is what we are looking at earlier right? Ryan.\\nRyan Richards:\\nWhich 1, are you referring to.\\nNathan Hess:\\nThe share.\\nUh, and the Android device data.\\nRyan Richards:\\nUh, well, I don't think that was particular to February, so.\\nWe yeah, we pull the topics. Sorry.\\nUm, pulled.\\nThe share viewership coming from set top box and then our apps.\\nAnd with whatever data fixes happen, and it seems to have.\\nSignificantly changed those from what we had as a.\\nAs recently a couple of months ago, I think.\\nUm, so now, FDA is like, 32, almost of all of our viewership.\\nOr set top boxes 68.\\nDoes that surprise you at all Jim and Julia?\\nGuillaume Schwengler:\\nWe had that number somewhere.\\nJulya Fridman:\\nBut it went from from the teams to 38%.\\nRyan Richards:\\nQ, and what was the, what was the latest percent you had on hand?\\nYou 1st shared with me uh, it was 24%.\\nKeelan Gallagher:\\nBut from an older dataset that we had pulled, I'm guessing in March.\\nRyan Richards:\\nYeah, oh, yeah, I see it on the thread now. So from March earlier this year that we had pulled 26%.\\nJulya Fridman:\\nHold on, it seems high to.\\nI have open somewhere.\\nSo overall.\\nAcross all networks set, top boxes. 83% is.\\nRyan Richards:\\nAll of our video new households. Oh, yeah. Is that households are viewing ours?\\nJulya Fridman:\\nOh, if possible, I, I believe it. Yeah, no uh, not not usage right? Households.\\nKeelan Gallagher:\\nAnd we can pull the usage, we can pull like, station hours.\\nJulya Fridman:\\nIf you can pull usage, uh, that would be.\\nUh, easier to compare. Okay.\\nGuillaume Schwengler:\\nThe latest number I found in 1 of the decks I heard was August 2022. I had usage, um, 16.\\nAnd the rest was set top box it changes a little bit by markets.\\nLike, Florida was most 17%, New York City.\\nJulya Fridman:\\nRelease I wouldn't expect any job. Like, it's just the.\\nRight. Like oh, wait, wait, wait, we fixed Android.\\nUh, in this data, right? Right.\\nUm, but that's but the Android issue started.\\nIn February, so if you compare it to January.\\nI mean, it should be in line.\\nRyan Richards:\\nAll right okay. And can you work with Jim? Can you just show them how you pull the data? The exact data you have? Because those numbers are and.\\nI want to get that straight, um.\\nKeelan Gallagher:\\nYeah, we'll pull we'll pull station hours and we'll we'll look at it at.\\nJulya Fridman:\\nYeah, Jim, Jim, you have different you, you've created different trending, right?\\nGuillaume Schwengler:\\nUh, I think, no, we had 1 is a pie chart when we tracked the launch of the apps where we had, I was coming from set the box I was coming from and I was coming from the up.\\nJulya Fridman:\\nBut then tracking it, but do you have anything more recent than, uh, since the launch of the apps? That would have been a few years ago, right?\\nGuillaume Schwengler:\\nThis 1 was the latest I was August 2022.\\nRight. Um, let's see, you.\\nJulya Fridman:\\nBut either way, I mean, if we pull January data and compare it to.\\nUm, the new restate the data it shouldn't directionally be dramatically different. I don't think.\\nKeelan Gallagher:\\nI'm running it right now. I'll probably know now, in a few minutes.\\nRyan Richards:\\nOkay on that topic I wanted to check in to see Julie. I think you said, oh, a little while back you're going to connect with someone on the latest from.\\nWhat Katy, Donna and her team, like next steps for power on on.\\nShe told me last week.\\nJulya Fridman:\\nUh, that she did not, uh, get anything back from Katie. Uh.\\nMaybe we just need to what, what exactly she is, she investigating.\\nThe pylon or the so.\\nRyan Richards:\\nFrom that last time that we all met together, it.\\nNathan, and, and step in here too, if there's anything I'm missing here, but the, what I recall is that on Apple TV, we, we need to switch up the rules for, like, what constitutes power on. Right?\\nBecause as it currently stands, you have to close out of the app for it to.\\nAnd power on to spectrum news. Okay. Um, so it's really about like, redefining what exactly power on means on the connected.\\nTv device apps that was specific to Apple TV, right?\\nYeah, but we should, we should make sure that it's aligned across all the platforms because.\\nWho knows for the other ones, if there's slight differences that could make a significant impact on the actual.\\nAmount of times people are saying spectrum is when it comes on.\\nJulya Fridman:\\nSo, it's basically, if you, if you get out of the app and then come back within a certain period of time.\\nIt doesn't, uh, power on you, uh, unless unless you've been out.\\nRyan Richards:\\nFor a certain number of hours, right? I mean, what I recall for Apple TV, I don't think there was an hour limit is like, you could be out of it for a week. And as long as you didn't actually close out of that app manually on the Apple TV.\\nInterface then you're still not going to power on to the spectrum news.\\nNathan Hess:\\nYeah, that's right. Yeah. I don't know about the week's part, but yeah, like that.\\nOurs could go by and you could do any number of other viewing events on other apps and come back.\\nTo the spectrum news app, or come back to and it would still power on 2.\\nGo back to what you were watching when you finished your last session.\\nJulya Fridman:\\nBecause then you wouldn't test with this. Yeah, we tested it pretty extensively with last fall.\\nNathan Hess:\\nShe had a whole list of, like, if Dan's that we went through, I can, I can.\\nProbably surface, at least my responses to that.\\nJulya Fridman:\\nAnd from Katie, WH, uh, what do we need from from Katie the confirmation or the, um.\\nRyan Richards:\\nNo, I don't think we need confirmation. We just need to know next steps of how we actually change the power on rules. And, like I wonder, I'm not sure if that's.\\nJulya Fridman:\\nDo you think that's Katie? I'm not sure. I think it's I think it's we need to go to the product person for Apple TV.\\nAnd work with them, shouldn't we? Uh, there was somebody, uh, when this whole Apple issue came up, um.\\nRocky ping me, and she had somebody on the on the call with her who was the product manager for Apple TV?\\nUm, I can see if I can get her name.\\nAnd maybe maybe we can just talk to her.\\nRyan Richards:\\nOkay, how it works.\\nJulya Fridman:\\nGet the product person.\\nOkay, let me let me look into it.\\nThanks, Sarah is so busy in her new world. It's like, impossible to get a hold of her. So, let me let me deal with it.\\nRyan Richards:\\nSounds good, thank you. Um.\\nWhat else heads up we.\\nYou got confirmation that the power on fix rolled out successfully last week, and they didn't see any notice will increase in call volume to call centers. So, that was good.\\nJulya Fridman:\\nUm, so we'll.\\nRyan Richards:\\nWait until the viewership data is good to pull. The recent may dealership. Data is good following this city upgrade and.\\nThen we can validate on our end that we're saying, hopefully.\\nThe impact of the fix perfect.\\nSighting yes, and also we were just our team was just meeting before this also exciting knowing that.\\nUh, there's definitely didn't fix everything, so hopefully we see a positive impact and then we regroup and figure out. All right what are the gaps.\\nThat we still see and get those addressed eventually.\\nYeah, 1 of our analysts moved to Florida in the fall and didn't get spec, news is power on and hers was not fixed last week. So.\\nWe know that there are issues post November like this fix was supposed to capture that whatever issues happen between March and November last year. Um, we know that there have been continued issues since November per the data.\\nThat and analysis you all did, and anecdotally.\\nFor example, Mike, a month or so ago, getting his new box in and not coming with spectrum uses power on in New York City.\\nUm, and then clearly, there's at least 1 person who, even in that period of last year didn't get there is fixed. So.\\nMore to come.\\nJulya Fridman:\\nSounds good Nathan. Anything else on your end.\\nNathan Hess:\\nNothing from me, How's that query? Coming along?\\nKeelan Gallagher:\\nIt's coming as soon as I guess I'll send it to the group if we're not still on the call.\\nYeah, I don't think I have.\\nNathan Hess:\\nAnything else top of mind.\\nFor a moment, we'll probably be reaching out.\\nYou have a bunch this week and next just to make sure that we're seeing the same stuff in the in the reloaded data, but.\\nAs long as you'll be around, we'll look forward to chatting with you and yeah. You know, we're hoping.\\nTo probably send out both March and april's engagement report. By the end of the month. I had initially said.\\nThe 19th, but I don't think that's gonna happen. So if we can get it out by the.\\n2526 or 31st that'd be great.\\nYeah, and are you taking any sorry? Are you taking any time off for Memorial day, or you'd be around.\\nTo validate, I'll do it around.\\nGuillaume Schwengler:\\nPriority number 1.\\nNathan Hess:\\nYeah, uh, Kim would, would you run your type.\\nJulya Fridman:\\nAnalysis of of the new data yes you can see.\\nThe gaps, yes, that way Jim has created like a tracker. That's.\\nI mean, it goes, it's it's not spectrum news specific. It's more just overall, um, to kind of.\\nUh, uh, and, uh, you know, hopefully some things will pop up.\\nIf, uh, some red flags, we'll, we'll see some red flags if there's.\\nAny data issue and then reload.\\nNathan Hess:\\nSo, I had had John wells load a mapping file that maps line up to spectrum news feed.\\nRegion and market in the sandbox, I mean, uh.\\nYeah, I'll share that link with you. It's helpful for a lot of our reporting takes out of Excel step for us. So, I mean, hopefully that mapping is current, but.\\nAndy, I need to have that environment.\\nGuillaume Schwengler:\\nNice and we're starting to see more and more relating to spectrum .\\nSo, we got keeping track of it for now, but you let us know how you want to report on it because we'll be able to add later on similar to how we do for spectrum use and Tableau. If you want to look at monthly.\\nIt'd be good to know. Yeah. I don't know.\\nNathan Hess:\\nYeah, I haven't I haven't personally, I thought.\\nI thought too deeply on what those reports might look like Ryan. I don't know if you have.\\nThoughts on that for plans.\\nRyan Richards:\\nNo, not yet. Not yet. Cool.\\nGuillaume Schwengler:\\nTbd, and with the apps, so the last quarter we had done by bundled so that we get more or less the same numbers. And what has.\\nIn order to know the product bundle of the app.\\nSo, we also keep updating that to see if there's a significant change for users or mobile app users, but we can.\\nAt least on the relative bases and index values, we could report on it. If you want it.\\nIs that sell for spectrum news plus? Or is this so India you have your ship for both that we see coming through the spectrum use local feed and then the spectrum use plus feed.\\nBut also, among our users authenticated users that are customers of charter over, we do the product bundle information as a customer to got it.\\nGot it cool.\\nNathan Hess:\\nAnything else I can walk on with Michael likes to say.\\nFor that John Mike, I think.\\nJulya Fridman:\\nYeah, we're good. Love that.\\nCool. Cool. Thanks guys. Well, hopefully, no data issues.\\nNathan Hess:\\nFingers crossed. Yeah. It seems like it's going well so far. So.\\nI was happy to see that the upgrade went through smoothly this morning. Everything was back up on line.\\nKim actually said that the DB seemed to be performing pretty well this morning. So.\\nI love that.\\nJulya Fridman:\\nThat'd be nice if there is, there was a side effect.\\nNathan Hess:\\nYeah, right yeah cleared out all the old zombie jobs.\\nJulya Fridman:\\nAll right cool. Talk to you guys soon.\\nRyan Richards:\\nHi guys bye.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = []\n",
    "previous_speaker = ''\n",
    "for line in lines: \n",
    "    newline = cleanLine(line)\n",
    "    if newline != None: \n",
    "        if newline[-1] == ':':\n",
    "            current_speaker = newline\n",
    "            if current_speaker != previous_speaker:\n",
    "                #print(newline) \n",
    "                previous_speaker = current_speaker\n",
    "                output.append(newline)\n",
    "        else: \n",
    "            #print(newline) \n",
    "            output.append(newline)\n",
    "final = '\\n'.join(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
